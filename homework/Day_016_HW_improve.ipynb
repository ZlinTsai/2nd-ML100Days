{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set path\n",
    "dir_data = '../../Lecture_data/'\n",
    "f_app_train = os.path.join(dir_data, 'application_train.csv')\n",
    "f_app_test = os.path.join(dir_data, 'application_test.csv')\n",
    "\n",
    "### Reading data\n",
    "app_train = pd.read_csv(f_app_train)\n",
    "app_test = pd.read_csv(f_app_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation = 15% train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46127, 122)\n",
      "(261384, 122)\n"
     ]
    }
   ],
   "source": [
    "app_validation = app_train.sample(frac = 0.15)\n",
    "app_train = app_train.drop(app_validation.index)\n",
    "print(app_validation.shape)\n",
    "print(app_train.shape)\n",
    "\n",
    "ans_validation = app_validation['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode for object(str) <=2 \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "# check all columns\n",
    "for col in app_train:\n",
    "    if app_train[col].dtype == 'object':\n",
    "        ### find object <= 2 into 0 and 1\n",
    "        if len(list(app_train[col].unique())) <= 2:\n",
    "            # Label Encoder\n",
    "            le.fit(app_train[col])\n",
    "            app_train[col] = le.transform(app_train[col])\n",
    "            app_validation[col] = le.transform(app_validation[col])\n",
    "            app_test[col] = le.transform(app_test[col])\n",
    "            \n",
    "            # recording\n",
    "            le_count += 1\n",
    "            \n",
    "# One Hot Encoding            \n",
    "app_train = pd.get_dummies(app_train)\n",
    "app_validation = pd.get_dummies(app_validation)\n",
    "app_test = pd.get_dummies(app_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 受雇日數為異常值的資料, 另外設一個欄位記錄, 並將異常的日數轉成空值 (np.nan)\n",
    "#app_train['DAYS_EMPLOYED_ANOM'] = (app_train[\"DAYS_EMPLOYED\"] == 365243)\n",
    "app_train['DAYS_EMPLOYED'].replace(365243, np.nan, inplace = True)\n",
    "app_validation['DAYS_EMPLOYED'].replace(365243, np.nan, inplace = True)\n",
    "#app_test['DAYS_EMPLOYED_ANOM'] = (app_test[\"DAYS_EMPLOYED\"] == 365243)\n",
    "app_test[\"DAYS_EMPLOYED\"].replace(365243, np.nan, inplace = True)\n",
    "\n",
    "\n",
    "# 出生日數 (DAYS_BIRTH) 取絕對值 \n",
    "app_train['DAYS_BIRTH'] = abs(app_train['DAYS_BIRTH'])\n",
    "app_validation['DAYS_BIRTH'] = abs(app_validation['DAYS_BIRTH'])\n",
    "app_test['DAYS_BIRTH'] = abs(app_test['DAYS_BIRTH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 做好前處理\n",
    "開始擬合模型之前，我們要確保 training & testing data 的欄位數量一致，原因是因為 One hot encoding 會製造多的欄位，有些類別出現在 training data 而沒有出現 testing data 中，我們就要把這些多餘的欄位去除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261384, 239)\n",
      "(46127, 239)\n",
      "(48744, 239)\n"
     ]
    }
   ],
   "source": [
    "train_labels = app_train['TARGET']\n",
    "\n",
    "# 調整欄位數, 移除出現在 training data 而沒有出現 testing data 中的欄位\n",
    "app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n",
    "app_train, app_validation = app_train.align(app_validation, join = 'inner', axis = 1)\n",
    "\n",
    "print(app_train.shape)\n",
    "print(app_validation.shape)\n",
    "print(app_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (261384, 239)\n",
      "Vaildation data shape:  (46127, 239)\n",
      "Testing data shape:  (48744, 239)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 特徵欄位清單 and copy\n",
    "train      = app_train.copy()\n",
    "validation = app_validation.copy()\n",
    "test       = app_test.copy()\n",
    "features   = list(train.columns)\n",
    "\n",
    "# 填補器 :  default=”mean” , 'median', 'most_frequent', 'constant'\n",
    "#If “constant”, then replace missing values with fill_value. Can be used with strings or numeric data.\n",
    "#SimpleImputer(missing_values=nan, strategy=’mean’, fill_value=None, verbose=0, copy=True) 不一定要nan\n",
    "imputer = SimpleImputer(strategy = 'mean')\n",
    "\n",
    "# 填補器載入個欄中位數\n",
    "imputer.fit(train)\n",
    "\n",
    "# 回填 train, test 資料中的空缺值\n",
    "train      = imputer.transform(train)\n",
    "validation = imputer.transform(validation)\n",
    "test       = imputer.transform(test)\n",
    "\n",
    "# 縮放器 : 設定特徵縮放到 -1 ~ 1 區間 (比 0 ~ 1得到更多分數)\n",
    "scaler = MinMaxScaler(feature_range = (-1, 1)) \n",
    "\n",
    "# scaler載入\n",
    "scaler.fit(train)\n",
    "\n",
    "# 縮放器載入 train 的上下限, 對 train, test 進行縮放轉換\n",
    "train      = scaler.transform(train)\n",
    "validation = scaler.transform(validation)\n",
    "test       = scaler.transform(test)\n",
    "\n",
    "print('Training data shape: ', train.shape)\n",
    "print('Vaildation data shape: ', validation.shape)\n",
    "print('Testing data shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use train data to compute any thing. [follow course](http://cs231n.github.io/neural-networks-2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 設定模型與模型參數\n",
    "log_reg = LogisticRegression(C = 0.0001, solver='lbfgs')\n",
    "\n",
    "# 使用 Train 資料訓練模型\n",
    "log_reg.fit(train, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型 fit 好以後，就可以用來預測 testing data 中的客戶違約遲繳貸款的機率咯! (記得要用 predict_proba 才會輸出機率)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09478138 0.04687912 0.13150006 ... 0.06424039 0.04537949 0.07971607]\n"
     ]
    }
   ],
   "source": [
    "log_reg_pred_vaildation = log_reg.predict_proba(validation)[:, 1]\n",
    "\n",
    "print(log_reg_pred_vaildation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        SK_ID_CURR  Prediction  TARGET\n",
      "296779      443839    0.094781       0\n",
      "299723      447231    0.046879       0\n",
      "96258       211753    0.131500       0\n",
      "68421       179361    0.073573       0\n",
      "70016       181219    0.151296       0\n",
      "40908       147374    0.080282       0\n",
      "2815        103285    0.106525       0\n",
      "53995       162561    0.098802       0\n",
      "293514      440044    0.070477       0\n",
      "196916      328320    0.043697       0\n"
     ]
    }
   ],
   "source": [
    "output = {'SK_ID_CURR': app_validation['SK_ID_CURR'], 'Prediction': log_reg_pred_vaildation, 'TARGET': ans_validation}\n",
    "df_vaildation = pd.DataFrame(output)\n",
    "print(df_vaildation.head(n = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# los function\n",
    "def loss(t, y):\n",
    "    return 0.5 * ((t - y)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1662.013583343985\n"
     ]
    }
   ],
   "source": [
    "loss_validation = loss(df_vaildation['Prediction'], df_vaildation['TARGET'])\n",
    "\n",
    "print(loss_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用模型預測結果\n",
    "# 請注意羅吉斯迴歸是分類預測 (會輸出 0 的機率, 與 1 的機率), 而我們只需要留下 1 的機率這排\n",
    "log_reg_pred = log_reg.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 儲存預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SK_ID_CURR    TARGET\n",
      "0      100001  0.058513\n",
      "1      100005  0.147313\n",
      "2      100013  0.052191\n",
      "3      100028  0.063996\n",
      "4      100038  0.130890\n"
     ]
    }
   ],
   "source": [
    "# 計算提交結果\n",
    "output = {'SK_ID_CURR': app_test['SK_ID_CURR'], 'TARGET': log_reg_pred}\n",
    "df = pd.DataFrame(output)\n",
    "print(df.head())\n",
    "#print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyFile = '../data/hw_016_test1.csv'\n",
    "df.to_csv(MyFile, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "\n",
    "* strategy = 'median' , C = 0.0001, solver='lbfgs' => Score = 0.70579 (loss = 1662.2524)\n",
    "\n",
    "* strategy = 'most_frequent' , C = 0.0001, solver='lbfgs' => Score = 0.70233 (loss = 1664.5252)\n",
    "\n",
    "* strategy = 'mean' , C = 0.0001, solver='lbfgs' => Score = 0.70595 (loss = 1662.0135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
